-=-=-= CC Capture on Sheeva 2009-09-17
SEE GDocs: SheevaPlug Installation Notes
  For details on kernel update!
  upgrade with pre-built 2.6.30.6 with usbserial/pl2303 modules

From cantor to sheeva on serial console
screen /dev/ttyUSB2 115200

Confirmed sheeva debian ubuntu has stty! we can use serialStamp.sh
mkdir -p /mirawatt
cd /mirawatt/
scp -p daniel@cantor.dl.sologlobe.com:netbeans-workspace/green/scalr-utils/CurrentCost/serialStamp.sh .
scp -p daniel@cantor.dl.sologlobe.com:netbeans-workspace/green/scalr-utils/CurrentCost/ParseStampedCC.py .
# Check: e745e80e529bae7572e05064ccd3eff5  serialStamp.sh
#  and   0ecf3e4ade1e859406b9fc7a33c82e98  ParseStampedCC.py

# Now run it
# chmod +x serialStamp.sh
cd /mirawatt/
/mirawatt/serialStamp.sh /dev/ttyUSB0 57600 CC1 &

Just Test the old Parser:
at /mirawatt/CC*log |   python /mirawatt/ParseStampedCC.py




-=-=-= CC Compare tests in 2009-07
So: daniel is partt of sudoers (wheel on fedora)
sudo chmod a+rw /dev/ttyUSB*
Or how about we run the script as root... on wrtsl54gs at least.

added setserial
  ipkg install setserial

Format USB on wrtsl54gs:
  ls -ld /dev/scsi/host0/bus0/target0/lun0/

  fdisk /dev/scsi/host0/bus0/target0/lun0/disc
   p - gives information on what partitions are on the device
   d - deletes any partitions that are present
   n - creates the new partition (default settings are fine)
   t - chooses the file system; b=fat32, recognized both by Windows and Linux
   w - writes the partition and exits

   no fstools.. go to vik to format
  mkfs.vfat -F 32 /dev/sdb1

TODO
  output to usb mass storage on wrtsl54gs with hub and three devices...

  tty should be reset WHEN ?
  Timeout loop is flaky ...

  Check that script fails if bad perms (ro, or none) on tty
  Check that speed is actuall reset...
    ** Unplug replug will do both of theese
  ADD DEBUGON echo to script!
  test by setting DEBUGOFF by hand....

All rolled into: /home/daniel/scalr-utils/CurrentCost/serialStamp.sh
/home/daniel/scalr-utils/CurrentCost/serialStamp.sh /dev/ttyUSB0 38400 AZ2 &
/home/daniel/scalr-utils/CurrentCost/serialStamp.sh /dev/ttyUSB1 57600 CC1 &
/home/daniel/scalr-utils/CurrentCost/serialStamp.sh /dev/ttyUSB2 57600 CC2 &
And CC3 (as CC2 for WaterHeater)
/home/daniel/scalr-utils/CurrentCost/serialStamp.sh /dev/ttyUSB2 57600 CC3H2O &


start comparing:
-run the parser:
  cd iMetricalData
  cat CC*log |   python ../scalr-utils/CurrentCost/ParseStampedCC.py 

rm coco.csv coco.sql
for i in FirstTrial/CC*stamp.log Hourly/CC*log CC*log; do 
    wc -l $i; 
    #make a big csv
    #cat $i | python ../scalr-utils/CurrentCost/ParseStampedCC.py|grep -v "^INSERT" >>coco.csv 
    # make a big sql
    cat $i | python ../scalr-utils/CurrentCost/ParseStampedCC.py|grep "^INSERT"  >>coco.sql
done

pump to cantor

mysqladmin create currentcost

DROP TABLE IF EXISTS `cc_native`;
CREATE TABLE `cc_native` (
  `stamp` datetime NOT NULL default '1970-01-01 00:00:00',
  `watt` int(11) NOT NULL default '0',
  `sensorid` varchar(255) default NULL,
  `ch1watt` int(11) NOT NULL default '0',
  `ch2watt` int(11) NOT NULL default '0',
  `drift` int(11) NOT NULL default '0',
  PRIMARY KEY  (`stamp`),
  KEY `byStampSensor` (`stamp`,`sensorid`),
  KEY `bySensorStamp` (`stamp`,`sensorid`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;

mysql currentcost


now some selects against ted.watt


cc_native, all sensors: as tabs
mysql currentcost -b -e "select cc.stamp as GMT,cc.sensorid as SensorID, cc.watt as CC, tt.watt as TED from cc_native cc,ted.watt tt where tt.stamp=cc.stamp order by cc.stamp;"

How about aggregates:

DROP TABLE IF EXISTS `cc_agg_minute`;
CREATE TABLE `cc_agg_minute` (
  `stamp` datetime NOT NULL default '1970-01-01 00:00:00',
  `watt_az` int(11) NOT NULL default '0',
  `watt_ted` int(11) NOT NULL default '0',
  `watt_cc1` int(11) NOT NULL default '0',
  `watt_cc2` int(11) NOT NULL default '0',
  `watt_cc1_ch1` int(11) NOT NULL default '0',
  `watt_cc1_ch2` int(11) NOT NULL default '0',
  `watt_cc2_ch1` int(11) NOT NULL default '0',
  `watt_cc2_ch2` int(11) NOT NULL default '0',
  PRIMARY KEY  (`stamp`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;

DROP TABLE IF EXISTS `cc_agg_tenminute`;
CREATE TABLE `cc_agg_tenminute` (
  `stamp` datetime NOT NULL default '1970-01-01 00:00:00',
  `watt_az` int(11) NOT NULL default '0',
  `watt_ted` int(11) NOT NULL default '0',
  `watt_cc1` int(11) NOT NULL default '0',
  `watt_cc2` int(11) NOT NULL default '0',
  `watt_cc1_ch1` int(11) NOT NULL default '0',
  `watt_cc1_ch2` int(11) NOT NULL default '0',
  `watt_cc2_ch1` int(11) NOT NULL default '0',
  `watt_cc2_ch2` int(11) NOT NULL default '0',
  PRIMARY KEY  (`stamp`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;

DROP TABLE IF EXISTS `cc_agg_hour`;
CREATE TABLE `cc_agg_hour` (
  `stamp` datetime NOT NULL default '1970-01-01 00:00:00',
  `watt_az` int(11) NOT NULL default '0',
  `watt_ted` int(11) NOT NULL default '0',
  `watt_cc1` int(11) NOT NULL default '0',
  `watt_cc2` int(11) NOT NULL default '0',
  `watt_cc1_ch1` int(11) NOT NULL default '0',
  `watt_cc1_ch2` int(11) NOT NULL default '0',
  `watt_cc2_ch1` int(11) NOT NULL default '0',
  `watt_cc2_ch2` int(11) NOT NULL default '0',
  PRIMARY KEY  (`stamp`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;


produce aggregates for minute and tenminute:
get min-max from cc_native : 2009-07-02 20:20:17 | 2009-07-07 17:57:16

select sensorid,count(*),min(stamp),max(stamp) from cc_native group by sensorid;
+----------+----------+---------------------+---------------------+
| sensorid | count(*) | min(stamp)          | max(stamp)          |
+----------+----------+---------------------+---------------------+
| 1214     |    62706 | 2009-07-02 20:20:17 | 2009-07-07 17:56:47 | 
| 3887     |     2165 | 2009-07-02 20:20:18 | 2009-07-03 00:54:26 | 
| 607      |    50411 | 2009-07-03 08:51:09 | 2009-07-07 17:57:16 | 
+----------+----------+---------------------+---------------------+

create entries:
  -Insert stamp  by select from cc_native
  -Update each value column through a temp table

# create all "minute' stamps from cc_native table
replace into cc_agg_minute(stamp) select concat(left(stamp,16),':00') as g from cc_native;

Use a temporary table:
CREATE TEMPORARY TABLE `cc_agg_temp` (
  `stamp` datetime NOT NULL default '1970-01-01 00:00:00',
  `watt` int(11) NOT NULL default '0',
  PRIMARY KEY  (`stamp`)
);

# add a where clause to speed thing up ted.watt.stamp>'2009-07-01'
delete from cc_agg_temp;
insert into cc_agg_temp(stamp,watt) 
  select concat(left(ted.watt.stamp,16),':00') as g, avg(watt) from ted.watt,cc_agg_minute where ted.watt.stamp>'2009-07-01' and concat(left(ted.watt.stamp,16),':00')=cc_agg_minute.stamp group by g;
update cc_agg_minute dst set watt_ted=(select src.watt from cc_agg_temp src where dst.stamp=src.stamp);

#cc1
delete from cc_agg_temp;
insert into cc_agg_temp(stamp,watt) select concat(left(src.stamp,16),':00') as g,avg(src.watt) from cc_native src where src.sensorid in (1214) group by g;
update cc_agg_minute dst set watt_cc1=(select src.watt from cc_agg_temp src where dst.stamp=src.stamp);
#cc2
delete from cc_agg_temp;
insert into cc_agg_temp(stamp,watt) select concat(left(src.stamp,16),':00') as g,avg(src.watt) from cc_native src where src.sensorid in (3887,607) group by g;
update cc_agg_minute dst set watt_cc2=(select src.watt from cc_agg_temp src where dst.stamp=src.stamp);
#cc1.ch1
delete from cc_agg_temp;
insert into cc_agg_temp(stamp,watt) select concat(left(src.stamp,16),':00') as g,avg(src.ch1watt) from cc_native src where src.sensorid in (1214) group by g;
update cc_agg_minute dst set watt_cc1_ch1=(select src.watt from cc_agg_temp src where dst.stamp=src.stamp);
#cc1.ch2
delete from cc_agg_temp;
insert into cc_agg_temp(stamp,watt) select concat(left(src.stamp,16),':00') as g,avg(src.ch2watt) from cc_native src where src.sensorid in (1214) group by g;
update cc_agg_minute dst set watt_cc1_ch2=(select src.watt from cc_agg_temp src where dst.stamp=src.stamp);
#cc2.ch1
delete from cc_agg_temp;
insert into cc_agg_temp(stamp,watt) select concat(left(src.stamp,16),':00') as g,avg(src.ch1watt) from cc_native src where src.sensorid in (3887,607) group by g;
update cc_agg_minute dst set watt_cc2_ch1=(select src.watt from cc_agg_temp src where dst.stamp=src.stamp);
#cc2.ch2
delete from cc_agg_temp;
insert into cc_agg_temp(stamp,watt) select concat(left(src.stamp,16),':00') as g,avg(src.ch2watt) from cc_native src where src.sensorid in (3887,607) group by g;
update cc_agg_minute dst set watt_cc2_ch2=(select src.watt from cc_agg_temp src where dst.stamp=src.stamp);

#check:
select * from cc_agg_minute limit 20;

replace into cc_agg_tenminute(stamp,watt_ted,watt_cc1,watt_cc2,watt_cc1_ch1,watt_cc1_ch2,watt_cc2_ch1,watt_cc2_ch2) 
 select concat(left(stamp,15),'0:00') as g, avg(watt_ted),avg(watt_cc1),avg(watt_cc2),avg(watt_cc1_ch1),avg(watt_cc1_ch2),avg(watt_cc2_ch1),avg(watt_cc2_ch2) 
 from cc_agg_minute group by g;


replace into cc_agg_hour(stamp,watt_ted,watt_cc1,watt_cc2,watt_cc1_ch1,watt_cc1_ch2,watt_cc2_ch1,watt_cc2_ch2) 
 select concat(left(stamp,13),':00:00') as g, avg(watt_ted),avg(watt_cc1),avg(watt_cc2),avg(watt_cc1_ch1),avg(watt_cc1_ch2),avg(watt_cc2_ch1),avg(watt_cc2_ch2) 
 from cc_agg_minute group by g;

mysql> select * from cc_agg_hour;
+---------------------+----------+----------+----------+--------------+--------------+--------------+--------------+
| stamp               | watt_ted | watt_cc1 | watt_cc2 | watt_cc1_ch1 | watt_cc1_ch2 | watt_cc2_ch1 | watt_cc2_ch2 |
+---------------------+----------+----------+----------+--------------+--------------+--------------+--------------+
| 2009-07-02 20:00:00 |     1390 |     1200 |     1212 |          595 |          605 |          628 |          584 | 
| 2009-07-02 21:00:00 |     1444 |     1162 |     1146 |          638 |          524 |          531 |          616 | 
| 2009-07-02 22:00:00 |     4977 |     4403 |     4664 |         1976 |         2427 |         2566 |         2098 | 
| 2009-07-02 23:00:00 |     2695 |     2390 |     2434 |         1165 |         1225 |         1240 |         1194 | 
| 2009-07-03 00:00:00 |     1334 |     1211 |     1106 |          587 |          623 |          577 |          529 | 
| 2009-07-03 01:00:00 |     1845 |     1569 |        0 |          858 |          711 |            0 |            0 | 
| 2009-07-03 02:00:00 |     3086 |     2649 |        0 |         1429 |         1220 |            0 |            0 | 
| 2009-07-03 03:00:00 |     1357 |     1195 |        0 |          742 |          453 |            0 |            0 | 
+---------------------+----------+----------+----------+--------------+--------------+--------------+--------------+



out to ONE tsv: split it back up in Google docs: split on header lines!

mysql currentcost -b -e "select * from cc_agg_hour" >agg_combined.tsv
mysql currentcost -b -e "select * from cc_agg_tenminute" >>agg_combined.tsv
mysql currentcost -b -e "select * from cc_agg_minute" >>agg_combined.tsv


Starting Aztech:
  connecting from vik-> mysql on cantor...
  mysql -e "grant all on *.* to daniel@192.168.5.226"
from vik:...

Time zone info: http://dev.mysql.com/doc/refman/5.1/en/time-zone-support.html
Load em up on cantor:
  mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root mysql
Wow:
 mysql mysql -e "select * from time_zone_name where Name like '%Montreal%'"
+------------------------+--------------+
| Name                   | Time_zone_id |
+------------------------+--------------+
| America/Montreal       |          154 | 
| posix/America/Montreal |          704 | 
| right/America/Montreal |         1255 | 
+------------------------+--------------+

Timezone offsets: straight interval math
	 mysql -h cantor ted -e "select stamp,stamp - interval 4 hour,watt from watt_hour where stamp>'2009-07-03'"
Using CONVERT_TZ(dt,from_tz,to_tz)
  mysql -h cantor ted -e "SELECT @@global.time_zone, @@session.time_zone;"

Round trip
mysql -h cantor ted -e "SELECT now(),CONVERT_TZ(now(),'America/Montreal','GMT'),CONVERT_TZ(CONVERT_TZ(now(),'America/Montreal','GMT'),'GMT','America/Montreal')""

This is how I can know that America/Montreal is My System Timezone
[daniel@cantor ~]$ md5sum /etc/localtime 
64defc8d6747feef853cd3abbc645116  /etc/localtime
[daniel@cantor ~]$ find /usr/share/zoneinfo/ -type f -exec md5sum {} \;|grep 64defc8d6747feef853cd3abbc645116
64defc8d6747feef853cd3abbc645116  /usr/share/zoneinfo/posix/America/Montreal
64defc8d6747feef853cd3abbc645116  /usr/share/zoneinfo/America/Montreal

Bingo: Confirm transitions at 2008-11-02, and 2009-03-08
mysql -h cantor ted -e "SELECT stamp as GMT,CONVERT_TZ(stamp,'GMT','America/Montreal') as Eastern,TIMEDIFF(CONVERT_TZ(stamp,'GMT','America/Montreal'),stamp) as UTCOFFSET, watt from watt_hour order by stamp"

+---------------------+---------------------+-----------+------+
| GMT                 | Eastern             | UTCOFFSET | watt |
+---------------------+---------------------+-----------+------+
| 2008-07-30 00:00:00 | 2008-07-29 20:00:00 | -04:00:00 |  596 | 
| 2008-11-02 05:00:00 | 2008-11-02 01:00:00 | -04:00:00 |  932 | 
| 2008-11-02 06:00:00 | 2008-11-02 01:00:00 | -05:00:00 | 1276 | 
| 2009-03-08 06:00:00 | 2009-03-08 01:00:00 | -05:00:00 | 1590 | 
| 2009-03-08 07:00:00 | 2009-03-08 03:00:00 | -04:00:00 | 1590 | 
| 2009-07-03 19:00:00 | 2009-07-03 15:00:00 | -04:00:00 |  496 | 
+---------------------+---------------------+-----------+------+

So now for info purposes, how are undefined time handled!
mysql -t -h cantor ted -e "select CONVERT_TZ('2008-11-02 01:30:00','America/Montreal','GMT')"
mysql -t -h cantor ted -e "select CONVERT_TZ('2009-03-08 02:00:00','America/Montreal','GMT')"

Ambiguous    2008-11-02 01:30:00 Eastern -> GMT: 2008-11-02 05:30:00 but it could have been 2008-11-02 06:30:00
   The Hole all maps to the instant:
Non-Existent 2009-03-08 02:00:00 Eastern -> GMT: 2009-03-08 07:00:00
	     2009-03-08 02:01:00 Eastern -> GMT: 2009-03-08 07:00:00
	     2009-03-08 02:30:00 Eastern -> GMT: 2009-03-08 07:00:00
	     2009-03-08 02:59:00 Eastern -> GMT: 2009-03-08 07:00:00
	     2009-03-08 03:00:00 Eastern -> GMT: 2009-03-08 07:00:00

mysql -t -h cantor ted -e "select (UNIX_TIMESTAMP('2009-03-09')-UNIX_TIMESTAMP('2009-03-08'))/3600"
  23.0000
mysql -t -h cantor ted -e "select (UNIX_TIMESTAMP('2008-11-03')-UNIX_TIMESTAMP('2008-11-02'))/3600"
  25.0000 

How about arithmetic: I THINK ARITHMETIC is TIMEZONE AGNOSTIC
 2009-03-08 00:59:00 + 2 minutes
 2008-11-02 00:59:00 + 2 minutes
mysql -t -h cantor ted -e "select '2009-03-08 00:59:00','2009-03-08 00:59:00'+interval 2 minute"
+---------------------+-----------------------------------------+
| 2009-03-08 00:59:00 | '2009-03-08 00:59:00'+interval 2 minute |
+---------------------+-----------------------------------------+
| 2009-03-08 00:59:00 | 2009-03-08 01:01:00                     | 
+---------------------+-----------------------------------------+
mysql -t -h cantor ted -e "select '2008-11-02 00:59:00','2008-11-02 00:59:00'+interval 2 minutes"
+---------------------+-----------------------------------------+
| 2008-11-02 00:59:00 | '2008-11-02 00:59:00'+interval 2 minute |
+---------------------+-----------------------------------------+
| 2008-11-02 00:59:00 | 2008-11-02 01:01:00                     | 
+---------------------+-----------------------------------------+

OK back to Aztech:
These are my stamped readings
grep "0400 \[R\]" AZ2-20090701T225132-0400.stamp.log | grep 23704002
Pick the first-last lines:
  By Hand: My stamp [R] type,meter id, wh/10,?, seconds since power,?,?,?,?,?,reading id
2009-07-02T16:20:17-0400 [R],07,23704002,3342918,10,82568,00,A,0B,28,06DB,1739
2009-07-03T15:13:26-0400 [R],07,23704002,3346280,10,165338,01,A,0B,2B,0997,2439
Math on time stamps:
165338 - 82568  = 82770 secnods between theese two readings
mysql -t -h cantor ted -e "select '2009-07-02 16:20:17'+ interval (165338 - 82568) second"
+---------------------------------------------------------+
| '2009-07-02 16:20:17'+ interval (165338 - 82568) second |
+---------------------------------------------------------+
| 2009-07-03 15:19:47                                     | 
+---------------------------------------------------------+
Close but not exact!

Now let's check avg power consumption on ted in that period:

and compare that agaist both readings: 3346280-3342918 (10wh)

mysql -t -h cantor ted -e "select avg(watt),min(stamp),max(stamp), UNIX_TIMESTAMP(max(stamp))-UNIX_TIMESTAMP(min(stamp)) as seconds,(UNIX_TIMESTAMP(max(stamp))-UNIX_TIMESTAMP(min(stamp)))*avg(watt)/3600/1000 as kWh_TED,(3346280-3342918)*10/1000 as kWh_AZ from watt where stamp >='2009-07-02 16:20:17' and stamp <'2009-07-03 15:13:26'"
+-----------+---------------------+---------------------+---------+-----------------+---------+
| avg(watt) | min(stamp)          | max(stamp)          | seconds | kWh_TED         | kWh_AZ  |
+-----------+---------------------+---------------------+---------+-----------------+---------+
| 1427.8363 | 2009-07-02 16:20:17 | 2009-07-03 15:13:25 |   82388 | 32.676826269422 | 33.6200 | 
+-----------+---------------------+---------------------+---------+-----------------+---------+

Old Reading:
              grep 23704002 ../scalr-utils/Aztech-data/Aztech-01.txt |head
2009-01-23 02:20:54 EST |Response|=  41 : 2008/09/23 15:26:22 New Unit ID= 23704002
2009-01-23 02:22:49 EST |Response|=  57 : [R],07,23704002,2790572,10,10362027,00,A,14,26,676F,26363
2009-01-23 02:23:22 EST |Response|=  57 : [R],07,23704002,2790572,10,10362061,00,A,14,2E,6774,26368
and thos from Aztech-02.txt (binary ???)
2009-01-23 04:14:18 EST |Response|=  53 : [R],07,23704002,2790799,10,60167,01,A,0B,23,08E7,2121


Parsing AZ Logdump:
  make datetime into gmt/utc but Aztech has no DST: always use GMT-4:00
  as oposed to using America/Montreal! e.g.
2009-07-07 03:01:00 =  mysql -h cantor currentcost -e "select CONVERT_TZ('2009-07-06 23:01:00','America/Montreal','GMT')"
2009-07-07 03:01:00 =  mysql -h cantor currentcost -e "select CONVERT_TZ('2009-07-06 23:01:00','-04:00','GMT')"
2009-01-07 04:01:00  = mysql -h cantor currentcost -e "select CONVERT_TZ('2009-01-06 23:01:00','America/Montreal','GMT')"
2009-01-07 03:01:00 =  mysql -h cantor currentcost -e "select CONVERT_TZ('2009-01-06 23:01:00','-04:00','GMT')"

DROP TABLE IF EXISTS `az_hour_logdump`;
CREATE TABLE `az_hour_logdump` (
  `stamp` datetime NOT NULL default '1970-01-01 00:00:00',
  `readingWh` int(11) NOT NULL default '0',
  `wattPrecedingHour` int(11) NOT NULL default '0',
  PRIMARY KEY  (`stamp`)
) ENGINE=MyISAM DEFAULT CHARSET=latin1;
 
and run as:

python ../scalr-utils/CurrentCost/ParseAZLogdump.py  < AZ1-LOGDUMP-20090706T235100-0400.log|mysql -h cantor currentcost -vvv

out to tsv:

mysql -h cantor currentcost -b -e "select az.stamp - interval 1 hour as GMT, tt.stamp as TEDGMT,CONVERT_TZ(tt.stamp,'GMT','America/Montreal') as Montreal, az.wattPrecedingHour as AZ_Wh,tt.watt as TED_Wh  from az_hour_logdump az, ted.watt_hour tt where (az.stamp - interval 1 hour) = tt.stamp" >TEDvsAZbyHour.tsv

Aggregate By Day

mysql -h cantor currentcost -b -e "select Left(CONVERT_TZ(tt.stamp,'GMT','America/Montreal'),10) as Montreal_day, avg(az.wattPrecedingHour)*24 as AZ_Wh,avg(tt.watt)*24 as TED_Wh  from az_hour_logdump az, ted.watt_hour tt where (az.stamp - interval 1 hour) = tt.stamp group by Montreal_day" >TEDvsAZbyDay.tsv

Redoing CurrentCostAggregates:
 TED vs AZ1 vs CC1 vs CC2




